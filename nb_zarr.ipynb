{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WD.datasets import Conditional_Dataset_Zarr\n",
    "import numpy as np\n",
    "import torch\n",
    "import zarr\n",
    "import torch\n",
    "from torch.utils.data import Sampler, RandomSampler, BatchSampler, SequentialSampler\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zarr.open(\"/data/compoundx/WeatherDiff/model_input/7E2101_test.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/inputs/data</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(2917, 1, 32, 64)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(2917, 1, 32, 64)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">None</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">23896064 (22.8M)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">23896438 (22.8M)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">1.0</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">1/1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /inputs/data\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (2917, 1, 32, 64)\n",
       "Chunk shape        : (2917, 1, 32, 64)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : None\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 23896064 (22.8M)\n",
       "No. bytes stored   : 23896438 (22.8M)\n",
       "Storage ratio      : 1.0\n",
       "Chunks initialized : 1/1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.inputs.data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditioning_indices(start_index, conditioning_timesteps, batch_size, max_index):\n",
    "    max_rel_index = max_index - start_index\n",
    "    return (np.arange(min(batch_size, max_rel_index))[:,None] + conditioning_timesteps).ravel() + start_index\n",
    "\n",
    "def get_target_indices(start_index, lead_time, batch_size, max_index):\n",
    "    max_rel_index = max_index - start_index\n",
    "    return (np.arange(min(batch_size, max_rel_index))[:,None] + lead_time).ravel() + start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterator(zarr_group, start, stop, batch_size, conditioning_timesteps, lead_time):\n",
    "    # careful when calculating number of samples!\n",
    "    array_inputs = zarr_group.inputs.data\n",
    "    array_targets = zarr_group.targets.data\n",
    "    array_constants = zarr_group.constants.data\n",
    "\n",
    "    assert stop <= array_inputs.shape[0] - lead_time\n",
    "    chunk_size = array_inputs.chunks[0]\n",
    "    effective_batchsize = batch_size - min(conditioning_timesteps) + lead_time\n",
    "    chunks_per_batch = np.ceil(effective_batchsize / chunk_size)\n",
    "\n",
    "    starts = np.arange(start, stop, batch_size)\n",
    "    current_chunk = -1\n",
    "    \n",
    "    for j in starts:\n",
    "        print(j, np.arange(j, min(j+batch_size, stop)))\n",
    "        if j >= (current_chunk+1) * chunk_size:\n",
    "            chunks_input = torch.tensor(array_inputs.oindex[np.arange(current_chunk * chunk_size, min((chunks_per_batch + 1 + current_chunk) * chunk_size, stop), dtype=int),:,:,:])\n",
    "            chunks_targets= torch.tensor(array_targets.oindex[np.arange(current_chunk * chunk_size, min((chunks_per_batch + 1 + current_chunk) * chunk_size, stop), dtype=int),:,:,:])\n",
    "            current_chunk = j // chunk_size\n",
    "\n",
    "        input_data = chunks_input[get_conditioning_indices(j, conditioning_timesteps=conditioning_timesteps, batch_size=batch_size, max_index=stop) % chunk_size]\n",
    "        input_data = input_data.view(-1, len(conditioning_timesteps)*input_data.shape[1], *input_data.shape[2:])\n",
    "        output_data = chunks_targets[get_target_indices(j, lead_time=lead_time, batch_size=batch_size, max_index=stop) % chunk_size]\n",
    "\n",
    "        input_data = torch.concatenate((input_data, torch.tensor(array_constants[:])[None,...].repeat(input_data.shape[0], 1, 1, 1)), dim=1)\n",
    "        yield input_data, output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zarr.open(\"/data/compoundx/WeatherDiff/model_input/9921EA_train.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m k, j \u001b[39min\u001b[39;00m iterator(a, \u001b[39m0\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m8\u001b[39m, [\u001b[39m0\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], lead_time\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(k\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iterator' is not defined"
     ]
    }
   ],
   "source": [
    "for k, j in iterator(a, 0, 100, 8, [0,-1,-2], lead_time=2):\n",
    "    print(k.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WD.datasets import Conditional_Dataset_Zarr_Iterable, Conditional_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "from WD.datasets import write_conditional_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the dataloaders return the same values in the unshuffled case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Conditional_Dataset_Zarr_Iterable(zarr_file_path=\"/data/compoundx/WeatherDiff/model_input/079A9C_test.zarr\", config_file_path=\"/data/compoundx/WeatherDiff/config_file/079A9C.yml\", shuffle_chunks=False, shuffle_in_chunks=False)\n",
    "ds2 = Conditional_Dataset(pt_file_path=\"/data/compoundx/WeatherDiff/model_input/278771_test.pt\", config_file_path=\"/data/compoundx/WeatherDiff/config_file/278771.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=500)\n",
    "dl2 = DataLoader(ds2, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for (input1, target1), (input2, target2, _) in zip(dl, dl2):\n",
    "    \n",
    "    print((input1[:,0:10,...] == input2[:,0:10,...]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.8375, 0.8378, 0.8381,  ..., 0.8368, 0.8370, 0.8372],\n",
       "           [0.8301, 0.8311, 0.8322,  ..., 0.8296, 0.8293, 0.8295],\n",
       "           [0.8197, 0.8212, 0.8228,  ..., 0.8174, 0.8182, 0.8190],\n",
       "           ...,\n",
       "           [0.3430, 0.3356, 0.3279,  ..., 0.3634, 0.3569, 0.3503],\n",
       "           [0.3535, 0.3460, 0.3386,  ..., 0.3729, 0.3663, 0.3601],\n",
       "           [0.3795, 0.3765, 0.3737,  ..., 0.3889, 0.3857, 0.3826]],\n",
       " \n",
       "          [[0.4548, 0.4558, 0.4567,  ..., 0.4532, 0.4536, 0.4541],\n",
       "           [0.4362, 0.4403, 0.4454,  ..., 0.4319, 0.4313, 0.4330],\n",
       "           [0.4228, 0.4295, 0.4417,  ..., 0.4248, 0.4213, 0.4200],\n",
       "           ...,\n",
       "           [0.3437, 0.3332, 0.3205,  ..., 0.3654, 0.3592, 0.3520],\n",
       "           [0.3449, 0.3348, 0.3242,  ..., 0.3773, 0.3672, 0.3559],\n",
       "           [0.3449, 0.3396, 0.3344,  ..., 0.3605, 0.3553, 0.3501]],\n",
       " \n",
       "          [[0.5007, 0.5023, 0.5041,  ..., 0.4980, 0.4986, 0.4996],\n",
       "           [0.4711, 0.4791, 0.4884,  ..., 0.4652, 0.4642, 0.4662],\n",
       "           [0.4607, 0.4662, 0.4744,  ..., 0.4597, 0.4560, 0.4538],\n",
       "           ...,\n",
       "           [0.4682, 0.4546, 0.4374,  ..., 0.4937, 0.4864, 0.4784],\n",
       "           [0.4831, 0.4680, 0.4515,  ..., 0.5211, 0.5100, 0.4972],\n",
       "           [0.4556, 0.4491, 0.4426,  ..., 0.4742, 0.4684, 0.4621]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.5334, 0.5345, 0.5358,  ..., 0.5307, 0.5316, 0.5323],\n",
       "           [0.5044, 0.5124, 0.5217,  ..., 0.4978, 0.4962, 0.4986],\n",
       "           [0.4975, 0.5044, 0.5104,  ..., 0.4933, 0.4900, 0.4898],\n",
       "           ...,\n",
       "           [0.5090, 0.4907, 0.4692,  ..., 0.5486, 0.5369, 0.5239],\n",
       "           [0.5234, 0.5055, 0.4858,  ..., 0.5639, 0.5526, 0.5391],\n",
       "           [0.5124, 0.5055, 0.4989,  ..., 0.5318, 0.5256, 0.5190]],\n",
       " \n",
       "          [[0.5637, 0.5667, 0.5699,  ..., 0.5565, 0.5585, 0.5610],\n",
       "           [0.5320, 0.5426, 0.5538,  ..., 0.5156, 0.5146, 0.5213],\n",
       "           [0.5292, 0.5374, 0.5441,  ..., 0.5114, 0.5124, 0.5191],\n",
       "           ...,\n",
       "           [0.5744, 0.5568, 0.5359,  ..., 0.6175, 0.6034, 0.5890],\n",
       "           [0.5756, 0.5563, 0.5352,  ..., 0.6195, 0.6078, 0.5925],\n",
       "           [0.5491, 0.5411, 0.5332,  ..., 0.5716, 0.5642, 0.5568]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]],\n",
       " \n",
       " \n",
       "         [[[0.8378, 0.8382, 0.8386,  ..., 0.8366, 0.8370, 0.8374],\n",
       "           [0.8341, 0.8355, 0.8370,  ..., 0.8305, 0.8316, 0.8329],\n",
       "           [0.8239, 0.8261, 0.8281,  ..., 0.8183, 0.8200, 0.8216],\n",
       "           ...,\n",
       "           [0.3525, 0.3446, 0.3369,  ..., 0.3737, 0.3675, 0.3604],\n",
       "           [0.3563, 0.3496, 0.3425,  ..., 0.3791, 0.3720, 0.3640],\n",
       "           [0.3764, 0.3734, 0.3704,  ..., 0.3863, 0.3828, 0.3796]],\n",
       " \n",
       "          [[0.4461, 0.4470, 0.4483,  ..., 0.4439, 0.4444, 0.4451],\n",
       "           [0.4384, 0.4446, 0.4518,  ..., 0.4274, 0.4291, 0.4332],\n",
       "           [0.4295, 0.4423, 0.4600,  ..., 0.4198, 0.4189, 0.4220],\n",
       "           ...,\n",
       "           [0.3551, 0.3451, 0.3337,  ..., 0.3780, 0.3704, 0.3633],\n",
       "           [0.3490, 0.3388, 0.3281,  ..., 0.3772, 0.3684, 0.3590],\n",
       "           [0.3350, 0.3305, 0.3262,  ..., 0.3485, 0.3440, 0.3393]],\n",
       " \n",
       "          [[0.4897, 0.4915, 0.4935,  ..., 0.4858, 0.4868, 0.4882],\n",
       "           [0.4721, 0.4821, 0.4903,  ..., 0.4572, 0.4591, 0.4640],\n",
       "           [0.4629, 0.4733, 0.4866,  ..., 0.4521, 0.4501, 0.4556],\n",
       "           ...,\n",
       "           [0.4950, 0.4844, 0.4699,  ..., 0.5045, 0.5031, 0.5009],\n",
       "           [0.4795, 0.4646, 0.4497,  ..., 0.5172, 0.5056, 0.4931],\n",
       "           [0.4260, 0.4179, 0.4095,  ..., 0.4468, 0.4405, 0.4336]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.5212, 0.5232, 0.5254,  ..., 0.5172, 0.5183, 0.5197],\n",
       "           [0.4949, 0.5051, 0.5146,  ..., 0.4812, 0.4814, 0.4865],\n",
       "           [0.4845, 0.4905, 0.4984,  ..., 0.4754, 0.4723, 0.4772],\n",
       "           ...,\n",
       "           [0.5219, 0.5068, 0.4880,  ..., 0.5506, 0.5429, 0.5340],\n",
       "           [0.5301, 0.5113, 0.4918,  ..., 0.5741, 0.5617, 0.5471],\n",
       "           [0.4909, 0.4838, 0.4770,  ..., 0.5108, 0.5044, 0.4975]],\n",
       " \n",
       "          [[0.5538, 0.5578, 0.5620,  ..., 0.5446, 0.5473, 0.5506],\n",
       "           [0.5216, 0.5322, 0.5431,  ..., 0.4978, 0.5002, 0.5097],\n",
       "           [0.5129, 0.5230, 0.5320,  ..., 0.4906, 0.4923, 0.5017],\n",
       "           ...,\n",
       "           [0.5855, 0.5704, 0.5518,  ..., 0.6163, 0.6061, 0.5964],\n",
       "           [0.5818, 0.5597, 0.5364,  ..., 0.6269, 0.6153, 0.6004],\n",
       "           [0.5228, 0.5151, 0.5077,  ..., 0.5456, 0.5382, 0.5305]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]],\n",
       " \n",
       " \n",
       "         [[[0.8351, 0.8354, 0.8358,  ..., 0.8342, 0.8344, 0.8347],\n",
       "           [0.8324, 0.8336, 0.8346,  ..., 0.8292, 0.8300, 0.8311],\n",
       "           [0.8241, 0.8257, 0.8278,  ..., 0.8194, 0.8206, 0.8223],\n",
       "           ...,\n",
       "           [0.3543, 0.3466, 0.3387,  ..., 0.3760, 0.3690, 0.3616],\n",
       "           [0.3557, 0.3487, 0.3423,  ..., 0.3770, 0.3698, 0.3627],\n",
       "           [0.3780, 0.3752, 0.3726,  ..., 0.3869, 0.3838, 0.3809]],\n",
       " \n",
       "          [[0.4405, 0.4418, 0.4432,  ..., 0.4372, 0.4382, 0.4392],\n",
       "           [0.4433, 0.4514, 0.4604,  ..., 0.4284, 0.4315, 0.4368],\n",
       "           [0.4373, 0.4520, 0.4682,  ..., 0.4211, 0.4220, 0.4275],\n",
       "           ...,\n",
       "           [0.3548, 0.3466, 0.3367,  ..., 0.3762, 0.3690, 0.3619],\n",
       "           [0.3421, 0.3317, 0.3210,  ..., 0.3706, 0.3611, 0.3518],\n",
       "           [0.3350, 0.3311, 0.3274,  ..., 0.3478, 0.3434, 0.3391]],\n",
       " \n",
       "          [[0.4799, 0.4825, 0.4852,  ..., 0.4738, 0.4754, 0.4776],\n",
       "           [0.4737, 0.4817, 0.4897,  ..., 0.4568, 0.4597, 0.4650],\n",
       "           [0.4715, 0.4839, 0.4948,  ..., 0.4530, 0.4542, 0.4627],\n",
       "           ...,\n",
       "           [0.4986, 0.4893, 0.4778,  ..., 0.5101, 0.5086, 0.5050],\n",
       "           [0.4656, 0.4507, 0.4358,  ..., 0.5047, 0.4929, 0.4793],\n",
       "           [0.4262, 0.4228, 0.4201,  ..., 0.4385, 0.4342, 0.4301]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.5159, 0.5183, 0.5210,  ..., 0.5095, 0.5115, 0.5135],\n",
       "           [0.4960, 0.5057, 0.5137,  ..., 0.4728, 0.4759, 0.4843],\n",
       "           [0.4847, 0.4953, 0.5097,  ..., 0.4679, 0.4688, 0.4770],\n",
       "           ...,\n",
       "           [0.5467, 0.5354, 0.5181,  ..., 0.5579, 0.5555, 0.5528],\n",
       "           [0.5214, 0.5042, 0.4878,  ..., 0.5677, 0.5540, 0.5380],\n",
       "           [0.4708, 0.4615, 0.4517,  ..., 0.4931, 0.4865, 0.4790]],\n",
       " \n",
       "          [[0.5483, 0.5523, 0.5565,  ..., 0.5377, 0.5409, 0.5446],\n",
       "           [0.5191, 0.5290, 0.5399,  ..., 0.4883, 0.4940, 0.5074],\n",
       "           [0.5119, 0.5243, 0.5354,  ..., 0.4829, 0.4874, 0.4985],\n",
       "           ...,\n",
       "           [0.6026, 0.5910, 0.5734,  ..., 0.6182, 0.6145, 0.6101],\n",
       "           [0.5647, 0.5431, 0.5233,  ..., 0.6192, 0.6039, 0.5848],\n",
       "           [0.5084, 0.4988, 0.4886,  ..., 0.5325, 0.5250, 0.5171]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.3612, 0.3611, 0.3610,  ..., 0.3615, 0.3615, 0.3614],\n",
       "           [0.3799, 0.3801, 0.3804,  ..., 0.3799, 0.3799, 0.3799],\n",
       "           [0.4139, 0.4149, 0.4161,  ..., 0.4096, 0.4112, 0.4127],\n",
       "           ...,\n",
       "           [0.7996, 0.8003, 0.8014,  ..., 0.7990, 0.7991, 0.7992],\n",
       "           [0.8022, 0.8014, 0.8007,  ..., 0.8047, 0.8039, 0.8031],\n",
       "           [0.8007, 0.8001, 0.7995,  ..., 0.8024, 0.8018, 0.8012]],\n",
       " \n",
       "          [[0.2807, 0.2806, 0.2803,  ..., 0.2808, 0.2810, 0.2808],\n",
       "           [0.2875, 0.2934, 0.3004,  ..., 0.2825, 0.2819, 0.2837],\n",
       "           [0.2987, 0.3161, 0.3361,  ..., 0.2644, 0.2724, 0.2840],\n",
       "           ...,\n",
       "           [0.4965, 0.4913, 0.4867,  ..., 0.5131, 0.5076, 0.5020],\n",
       "           [0.4834, 0.4757, 0.4681,  ..., 0.5046, 0.4977, 0.4908],\n",
       "           [0.4767, 0.4718, 0.4669,  ..., 0.4910, 0.4864, 0.4815]],\n",
       " \n",
       "          [[0.3628, 0.3626, 0.3626,  ..., 0.3630, 0.3630, 0.3628],\n",
       "           [0.3683, 0.3744, 0.3812,  ..., 0.3542, 0.3567, 0.3622],\n",
       "           [0.3787, 0.3938, 0.4118,  ..., 0.3387, 0.3479, 0.3648],\n",
       "           ...,\n",
       "           [0.5908, 0.5802, 0.5698,  ..., 0.6308, 0.6171, 0.6024],\n",
       "           [0.5822, 0.5688, 0.5533,  ..., 0.6138, 0.6043, 0.5941],\n",
       "           [0.5514, 0.5427, 0.5337,  ..., 0.5739, 0.5671, 0.5594]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4011, 0.4022, 0.4031,  ..., 0.3989, 0.3995, 0.4002],\n",
       "           [0.4028, 0.4088, 0.4148,  ..., 0.3862, 0.3891, 0.3958],\n",
       "           [0.4104, 0.4223, 0.4365,  ..., 0.3893, 0.3913, 0.3995],\n",
       "           ...,\n",
       "           [0.6276, 0.6172, 0.6073,  ..., 0.6652, 0.6515, 0.6389],\n",
       "           [0.6292, 0.6132, 0.5944,  ..., 0.6619, 0.6520, 0.6416],\n",
       "           [0.6101, 0.6026, 0.5942,  ..., 0.6283, 0.6228, 0.6168]],\n",
       " \n",
       "          [[0.4608, 0.4643, 0.4665,  ..., 0.4469, 0.4512, 0.4559],\n",
       "           [0.4474, 0.4561, 0.4663,  ..., 0.4204, 0.4296, 0.4383],\n",
       "           [0.4566, 0.4660, 0.4769,  ..., 0.4318, 0.4341, 0.4440],\n",
       "           ...,\n",
       "           [0.6728, 0.6621, 0.6517,  ..., 0.7112, 0.6976, 0.6847],\n",
       "           [0.6797, 0.6638, 0.6443,  ..., 0.7147, 0.7050, 0.6926],\n",
       "           [0.6586, 0.6505, 0.6415,  ..., 0.6785, 0.6728, 0.6661]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]],\n",
       " \n",
       " \n",
       "         [[[0.3572, 0.3570, 0.3567,  ..., 0.3574, 0.3574, 0.3574],\n",
       "           [0.3776, 0.3775, 0.3773,  ..., 0.3772, 0.3775, 0.3776],\n",
       "           [0.4146, 0.4152, 0.4148,  ..., 0.4095, 0.4113, 0.4133],\n",
       "           ...,\n",
       "           [0.7992, 0.7997, 0.8005,  ..., 0.7985, 0.7982, 0.7987],\n",
       "           [0.7992, 0.7983, 0.7974,  ..., 0.8027, 0.8016, 0.8004],\n",
       "           [0.7995, 0.7988, 0.7980,  ..., 0.8019, 0.8011, 0.8003]],\n",
       " \n",
       "          [[0.2737, 0.2737, 0.2736,  ..., 0.2730, 0.2735, 0.2736],\n",
       "           [0.2819, 0.2881, 0.2951,  ..., 0.2759, 0.2750, 0.2771],\n",
       "           [0.2856, 0.2997, 0.3176,  ..., 0.2599, 0.2662, 0.2747],\n",
       "           ...,\n",
       "           [0.4953, 0.4898, 0.4844,  ..., 0.5139, 0.5076, 0.5013],\n",
       "           [0.4835, 0.4742, 0.4641,  ..., 0.5083, 0.5003, 0.4921],\n",
       "           [0.4762, 0.4708, 0.4656,  ..., 0.4923, 0.4869, 0.4816]],\n",
       " \n",
       "          [[0.3551, 0.3551, 0.3551,  ..., 0.3545, 0.3549, 0.3551],\n",
       "           [0.3632, 0.3714, 0.3793,  ..., 0.3481, 0.3514, 0.3563],\n",
       "           [0.3624, 0.3791, 0.3999,  ..., 0.3302, 0.3404, 0.3512],\n",
       "           ...,\n",
       "           [0.5935, 0.5831, 0.5729,  ..., 0.6320, 0.6175, 0.6049],\n",
       "           [0.5767, 0.5629, 0.5461,  ..., 0.6128, 0.6006, 0.5888],\n",
       "           [0.5410, 0.5317, 0.5219,  ..., 0.5667, 0.5584, 0.5498]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.3966, 0.3978, 0.3989,  ..., 0.3938, 0.3947, 0.3955],\n",
       "           [0.4104, 0.4157, 0.4210,  ..., 0.3896, 0.3958, 0.4037],\n",
       "           [0.4150, 0.4298, 0.4466,  ..., 0.3840, 0.3911, 0.4031],\n",
       "           ...,\n",
       "           [0.6371, 0.6270, 0.6161,  ..., 0.6732, 0.6597, 0.6475],\n",
       "           [0.6340, 0.6203, 0.6035,  ..., 0.6650, 0.6555, 0.6455],\n",
       "           [0.5940, 0.5851, 0.5756,  ..., 0.6157, 0.6093, 0.6020]],\n",
       " \n",
       "          [[0.4561, 0.4588, 0.4608,  ..., 0.4425, 0.4467, 0.4512],\n",
       "           [0.4539, 0.4618, 0.4720,  ..., 0.4286, 0.4378, 0.4457],\n",
       "           [0.4618, 0.4745, 0.4883,  ..., 0.4284, 0.4358, 0.4479],\n",
       "           ...,\n",
       "           [0.6871, 0.6765, 0.6656,  ..., 0.7209, 0.7080, 0.6973],\n",
       "           [0.6859, 0.6710, 0.6529,  ..., 0.7184, 0.7090, 0.6981],\n",
       "           [0.6405, 0.6321, 0.6232,  ..., 0.6611, 0.6549, 0.6480]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]],\n",
       " \n",
       " \n",
       "         [[[0.3523, 0.3522, 0.3521,  ..., 0.3523, 0.3523, 0.3524],\n",
       "           [0.3733, 0.3733, 0.3735,  ..., 0.3741, 0.3737, 0.3734],\n",
       "           [0.4114, 0.4126, 0.4143,  ..., 0.4075, 0.4088, 0.4101],\n",
       "           ...,\n",
       "           [0.8001, 0.8000, 0.8003,  ..., 0.8011, 0.8004, 0.8001],\n",
       "           [0.8019, 0.8004, 0.7989,  ..., 0.8062, 0.8047, 0.8034],\n",
       "           [0.8034, 0.8027, 0.8021,  ..., 0.8056, 0.8048, 0.8042]],\n",
       " \n",
       "          [[0.2642, 0.2642, 0.2640,  ..., 0.2639, 0.2640, 0.2642],\n",
       "           [0.2700, 0.2762, 0.2832,  ..., 0.2625, 0.2624, 0.2653],\n",
       "           [0.2721, 0.2864, 0.3043,  ..., 0.2465, 0.2524, 0.2610],\n",
       "           ...,\n",
       "           [0.4917, 0.4861, 0.4807,  ..., 0.5121, 0.5050, 0.4980],\n",
       "           [0.4831, 0.4722, 0.4607,  ..., 0.5126, 0.5031, 0.4934],\n",
       "           [0.4804, 0.4752, 0.4705,  ..., 0.4967, 0.4912, 0.4857]],\n",
       " \n",
       "          [[0.3451, 0.3451, 0.3449,  ..., 0.3440, 0.3445, 0.3449],\n",
       "           [0.3534, 0.3610, 0.3689,  ..., 0.3343, 0.3379, 0.3457],\n",
       "           [0.3441, 0.3598, 0.3793,  ..., 0.3139, 0.3220, 0.3306],\n",
       "           ...,\n",
       "           [0.5951, 0.5857, 0.5767,  ..., 0.6265, 0.6155, 0.6051],\n",
       "           [0.5690, 0.5523, 0.5325,  ..., 0.6114, 0.5975, 0.5837],\n",
       "           [0.5325, 0.5225, 0.5141,  ..., 0.5637, 0.5539, 0.5433]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.3887, 0.3898, 0.3907,  ..., 0.3854, 0.3865, 0.3876],\n",
       "           [0.4033, 0.4090, 0.4155,  ..., 0.3862, 0.3929, 0.3982],\n",
       "           [0.4017, 0.4163, 0.4338,  ..., 0.3752, 0.3832, 0.3922],\n",
       "           ...,\n",
       "           [0.6471, 0.6356, 0.6230,  ..., 0.6767, 0.6679, 0.6575],\n",
       "           [0.6243, 0.6097, 0.5927,  ..., 0.6606, 0.6489, 0.6371],\n",
       "           [0.5790, 0.5701, 0.5610,  ..., 0.6048, 0.5964, 0.5878]],\n",
       " \n",
       "          [[0.4492, 0.4514, 0.4534,  ..., 0.4360, 0.4400, 0.4445],\n",
       "           [0.4455, 0.4544, 0.4653,  ..., 0.4254, 0.4316, 0.4373],\n",
       "           [0.4494, 0.4593, 0.4725,  ..., 0.4194, 0.4284, 0.4380],\n",
       "           ...,\n",
       "           [0.6981, 0.6871, 0.6740,  ..., 0.7268, 0.7201, 0.7100],\n",
       "           [0.6777, 0.6621, 0.6440,  ..., 0.7132, 0.7025, 0.6906],\n",
       "           [0.6212, 0.6133, 0.6051,  ..., 0.6425, 0.6358, 0.6286]],\n",
       " \n",
       "          [[0.5303, 0.5418, 0.5530,  ..., 0.5017, 0.5134, 0.5218],\n",
       "           [0.4418, 0.4891, 0.5144,  ..., 0.3452, 0.3898, 0.4097],\n",
       "           [0.5703, 0.6266, 0.6710,  ..., 0.2324, 0.4366, 0.5165],\n",
       "           ...,\n",
       "           [0.0058, 0.0059, 0.0058,  ..., 0.0068, 0.0059, 0.0059],\n",
       "           [0.0059, 0.0060, 0.0057,  ..., 0.0334, 0.0133, 0.0054],\n",
       "           [0.0059, 0.0059, 0.0060,  ..., 0.0061, 0.0058, 0.0058]]]]),\n",
       " tensor([[[[0.4929, 0.4946, 0.4962,  ..., 0.4878, 0.4893, 0.4911],\n",
       "           [0.5001, 0.5005, 0.5033,  ..., 0.4903, 0.4941, 0.4980],\n",
       "           [0.4778, 0.4758, 0.4752,  ..., 0.4778, 0.4764, 0.4768],\n",
       "           ...,\n",
       "           [0.4831, 0.5145, 0.5384,  ..., 0.4411, 0.4560, 0.4621],\n",
       "           [0.4691, 0.4780, 0.4858,  ..., 0.4262, 0.4434, 0.4576],\n",
       "           [0.4689, 0.4703, 0.4715,  ..., 0.4642, 0.4658, 0.4674]]],\n",
       " \n",
       " \n",
       "         [[[0.4939, 0.4964, 0.4990,  ..., 0.4854, 0.4882, 0.4909],\n",
       "           [0.4890, 0.4935, 0.5007,  ..., 0.4897, 0.4919, 0.4911],\n",
       "           [0.4780, 0.4752, 0.4758,  ..., 0.4841, 0.4805, 0.4797],\n",
       "           ...,\n",
       "           [0.4589, 0.4686, 0.5064,  ..., 0.4305, 0.4432, 0.4558],\n",
       "           [0.4607, 0.4713, 0.4803,  ..., 0.4291, 0.4381, 0.4487],\n",
       "           [0.4601, 0.4609, 0.4615,  ..., 0.4572, 0.4582, 0.4591]]],\n",
       " \n",
       " \n",
       "         [[[0.4958, 0.4986, 0.5011,  ..., 0.4878, 0.4903, 0.4931],\n",
       "           [0.4895, 0.4966, 0.5050,  ..., 0.4925, 0.4925, 0.4893],\n",
       "           [0.4758, 0.4740, 0.4758,  ..., 0.4876, 0.4835, 0.4801],\n",
       "           ...,\n",
       "           [0.4689, 0.4801, 0.4972,  ..., 0.4336, 0.4448, 0.4570],\n",
       "           [0.4540, 0.4591, 0.4646,  ..., 0.4387, 0.4432, 0.4479],\n",
       "           [0.4617, 0.4609, 0.4601,  ..., 0.4629, 0.4625, 0.4621]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.3377, 0.3392, 0.3404,  ..., 0.3314, 0.3337, 0.3359],\n",
       "           [0.3622, 0.3732, 0.3810,  ..., 0.3304, 0.3387, 0.3494],\n",
       "           [0.3859, 0.4063, 0.4144,  ..., 0.3316, 0.3510, 0.3663],\n",
       "           ...,\n",
       "           [0.5388, 0.5313, 0.5247,  ..., 0.5708, 0.5584, 0.5480],\n",
       "           [0.5207, 0.5031, 0.4854,  ..., 0.5733, 0.5567, 0.5386],\n",
       "           [0.5704, 0.5616, 0.5541,  ..., 0.6002, 0.5904, 0.5802]]],\n",
       " \n",
       " \n",
       "         [[[0.3447, 0.3461, 0.3475,  ..., 0.3383, 0.3406, 0.3428],\n",
       "           [0.3544, 0.3653, 0.3753,  ..., 0.3271, 0.3353, 0.3438],\n",
       "           [0.3930, 0.4060, 0.4144,  ..., 0.3457, 0.3691, 0.3830],\n",
       "           ...,\n",
       "           [0.5284, 0.5209, 0.5151,  ..., 0.5649, 0.5504, 0.5382],\n",
       "           [0.4835, 0.4678, 0.4523,  ..., 0.5421, 0.5196, 0.5003],\n",
       "           [0.5584, 0.5543, 0.5512,  ..., 0.5790, 0.5706, 0.5637]]],\n",
       " \n",
       " \n",
       "         [[[0.3481, 0.3496, 0.3512,  ..., 0.3422, 0.3443, 0.3463],\n",
       "           [0.3657, 0.3706, 0.3750,  ..., 0.3463, 0.3536, 0.3600],\n",
       "           [0.4007, 0.4140, 0.4228,  ..., 0.3563, 0.3765, 0.3901],\n",
       "           ...,\n",
       "           [0.5098, 0.5029, 0.4999,  ..., 0.5582, 0.5392, 0.5219],\n",
       "           [0.4603, 0.4432, 0.4313,  ..., 0.5245, 0.5045, 0.4819],\n",
       "           [0.5767, 0.5741, 0.5724,  ..., 0.5880, 0.5835, 0.5798]]]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ( == nenext(iter(dl2))[0]xt(iter(dl))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    print(a[i,0].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,10].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(next(iter(dl2))[0][0,0:10,...] == next(iter(dl))[0][0,0:10,...]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2b1d96caa8d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(next(iter(dl2))[0][0,10,...] - next(iter(dl))[0][0,10,...])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test zarr read speads.\n",
    "\n",
    "z = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test.zarr\",  mode='w', shape=(1e5, 1e4), chunks=(10000, 10000), compressor=None)\n",
    "\n",
    "z[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test.zarr\",  mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.oindex[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = zarr.open(\"/data/compoundx/WeatherDiff/model_input/079A9C_train.zarr/\",  mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test2.zarr\",  mode='w', shape=(54049, 5, 32, 64), chunks=(54049, 5, 32, 64), compressor=None)\n",
    "z2 = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test3.zarr\",  mode='w', shape=(54049, 5, 32, 64), chunks=(1, 5, 32, 64), compressor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1[:,:,:,:] = b.inputs.data[:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2[:,:,:,:] = b.inputs.data[:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z1[:,:,:,:] \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39;49minputs\u001b[39m.\u001b[39;49mdata[:,:,:,:]\n\u001b[1;32m      2\u001b[0m z1[:,:,:,:] \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mdata[:,:,:,:]\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/core.py:807\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    805\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvindex[selection]\n\u001b[1;32m    806\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 807\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_basic_selection(pure_selection, fields\u001b[39m=\u001b[39;49mfields)\n\u001b[1;32m    808\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/core.py:933\u001b[0m, in \u001b[0;36mArray.get_basic_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_basic_selection_zd(selection\u001b[39m=\u001b[39mselection, out\u001b[39m=\u001b[39mout,\n\u001b[1;32m    931\u001b[0m                                         fields\u001b[39m=\u001b[39mfields)\n\u001b[1;32m    932\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_basic_selection_nd(selection\u001b[39m=\u001b[39;49mselection, out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m    934\u001b[0m                                         fields\u001b[39m=\u001b[39;49mfields)\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/core.py:976\u001b[0m, in \u001b[0;36mArray._get_basic_selection_nd\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_basic_selection_nd\u001b[39m(\u001b[39mself\u001b[39m, selection, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fields\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    971\u001b[0m     \u001b[39m# implementation of basic selection for array with at least one dimension\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \n\u001b[1;32m    973\u001b[0m     \u001b[39m# setup indexer\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     indexer \u001b[39m=\u001b[39m BasicIndexer(selection, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_selection(indexer\u001b[39m=\u001b[39;49mindexer, out\u001b[39m=\u001b[39;49mout, fields\u001b[39m=\u001b[39;49mfields)\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/core.py:1267\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_store, \u001b[39m\"\u001b[39m\u001b[39mgetitems\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m   1262\u001b[0m    \u001b[39many\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)):\n\u001b[1;32m   1263\u001b[0m     \u001b[39m# sequentially get one key at a time from storage\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     \u001b[39mfor\u001b[39;00m chunk_coords, chunk_selection, out_selection \u001b[39min\u001b[39;00m indexer:\n\u001b[1;32m   1265\u001b[0m \n\u001b[1;32m   1266\u001b[0m         \u001b[39m# load chunk selection into output array\u001b[39;00m\n\u001b[0;32m-> 1267\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chunk_getitem(chunk_coords, chunk_selection, out, out_selection,\n\u001b[1;32m   1268\u001b[0m                             drop_axes\u001b[39m=\u001b[39;49mindexer\u001b[39m.\u001b[39;49mdrop_axes, fields\u001b[39m=\u001b[39;49mfields)\n\u001b[1;32m   1269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m     \u001b[39m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mindexer)\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/core.py:1966\u001b[0m, in \u001b[0;36mArray._chunk_getitem\u001b[0;34m(self, chunk_coords, chunk_selection, out, out_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   1962\u001b[0m ckey \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_key(chunk_coords)\n\u001b[1;32m   1964\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1965\u001b[0m     \u001b[39m# obtain compressed data for chunk\u001b[39;00m\n\u001b[0;32m-> 1966\u001b[0m     cdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_store[ckey]\n\u001b[1;32m   1968\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   1969\u001b[0m     \u001b[39m# chunk not initialized\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/storage.py:1072\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath, key)\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(filepath):\n\u001b[0;32m-> 1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fromfile(filepath)\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1074\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "File \u001b[0;32m~/.conda/envs/TORCH311/lib/python3.11/site-packages/zarr/storage.py:1047\u001b[0m, in \u001b[0;36mDirectoryStore._fromfile\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Read data from a file\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[39mfile reading logic.\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fn, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m-> 1047\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "z1[:,:,:,:] = b.inputs.data[:,:,:,:]\n",
    "z1[:,:,:,:] = b.inputs.data[:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test2.zarr\",  mode='r')\n",
    "test3 = zarr.open(\"/home/wider/Projects/diffusion-models-for-weather-prediction/test_zarr/test3.zarr\",  mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire chunk\n",
    "a = test2[:,:,:,:]\n",
    "\n",
    "for i in range(len(a)):\n",
    "    # access elements one time step at a time\n",
    "    a[i,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open one chunk at a time\n",
    "for i in range(test3.shape[0]):\n",
    "    # access elements one time step at a time\n",
    "    test3[i, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WD.io import load_config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conditional_Dataset_Zarr_Iterable(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, zarr_file_path, config_file_path, shuffle_chunks=False, shuffle_in_chunks=False):\n",
    "        super(Conditional_Dataset_Zarr_Iterable).__init__()\n",
    "        self.path = zarr_file_path\n",
    "        self.data = zarr.open(self.path, mode=\"r\")\n",
    "\n",
    "        self.array_inputs = self.data.inputs.data\n",
    "        self.array_targets = self.data.targets.data\n",
    "        self.array_constants = self.data.constants.data    \n",
    "\n",
    "        # we need to load the lead time and the conditioning time steps\n",
    "        config = load_config(config_file_path)\n",
    "        self.lead_time = config.data_specs.lead_time\n",
    "        self.conditioning_timesteps = torch.tensor(\n",
    "            config.data_specs.conditioning_time_step,\n",
    "            dtype=int,\n",
    "        )\n",
    "        self.max_abs_c_t = max(abs(self.conditioning_timesteps)).numpy()\n",
    "\n",
    "        self.chunk_size = self.array_targets.chunks[0]\n",
    "        self.n_chunks = self.array_targets.nchunks\n",
    "\n",
    "        self.start = self.max_abs_c_t\n",
    "        self.stop = self.array_targets.shape[0] - self.lead_time\n",
    "\n",
    "\n",
    "        self.indices = torch.ones(self.n_chunks*self.chunk_size, dtype=bool)\n",
    "        self.indices[:self.start] = False\n",
    "        self.indices[self.stop:] = False\n",
    "        self.indices = self.indices.view(self.n_chunks, self.chunk_size)\n",
    "\n",
    "        self.lat = self.data.targets.lat[:]\n",
    "        self.lon = self.data.targets.lon[:]\n",
    "\n",
    "        self.shuffle_chunks = shuffle_chunks\n",
    "        self.shuffle_in_chunks = shuffle_in_chunks\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        \n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            chunk_start = 0\n",
    "            chunk_stop = self.n_chunks\n",
    "        else:\n",
    "            per_worker = int(np.ceil(self.n_chunks / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            chunk_start = 0 + worker_id * per_worker\n",
    "            chunk_stop = min(chunk_start + per_worker, self.n_chunks)    \n",
    "            \n",
    "        if self.shuffle_chunks:\n",
    "            perm = np.random.permutation(np.arange(chunk_start, chunk_stop))\n",
    "        else:\n",
    "            perm = np.arange(chunk_start, chunk_stop)\n",
    "\n",
    "        n_previous_chunks_required_in_memory = np.ceil(self.max_abs_c_t / self.chunk_size).astype(int)\n",
    "        n_future_chunks_required_in_memory = np.ceil(self.lead_time / self.chunk_size).astype(int)\n",
    "\n",
    "        for i_chunk in perm:\n",
    "            valid_indices = torch.where(self.indices[i_chunk].ravel() == True)[0]\n",
    "            # print(torch.amin(valid_indices), torch.amax(valid_indices))\n",
    "            chunks_input = torch.tensor(self.array_inputs.oindex[np.arange(max((i_chunk - n_previous_chunks_required_in_memory) * self.chunk_size, 0), min((i_chunk + n_future_chunks_required_in_memory + 1)*self.chunk_size, self.array_inputs.shape[0]), dtype=int),:,:,:], dtype=torch.float)\n",
    "            chunks_targets = torch.tensor(self.array_targets.oindex[np.arange(max((i_chunk - n_previous_chunks_required_in_memory) * self.chunk_size, 0), min((i_chunk + n_future_chunks_required_in_memory + 1)*self.chunk_size, self.array_inputs.shape[0]), dtype=int),:,:,:], dtype=torch.float)\n",
    "\n",
    "            # depending on where we are in the chunks, a varying number of previous chunks can be loaded into memory. We need to compensate for this in our indexing.\n",
    "            i_offset = self.chunk_size * min(n_previous_chunks_required_in_memory, i_chunk)\n",
    "\n",
    "            if self.shuffle_in_chunks:\n",
    "                perm_in_chunk = valid_indices[torch.randperm(len(valid_indices))] + i_offset\n",
    "            else:\n",
    "                perm_in_chunk = valid_indices + i_offset\n",
    "\n",
    "            for i_in_chunk in perm_in_chunk:\n",
    "                input_data = chunks_input[self.get_conditioning_indices(i_in_chunk)]\n",
    "                input_data = input_data.view(len(self.conditioning_timesteps)*input_data.shape[1], *input_data.shape[2:])\n",
    "                output_data = chunks_targets[self.get_target_indices(i_in_chunk)]\n",
    "                input_data = torch.concatenate((input_data, torch.tensor(self.array_constants[:], dtype=torch.float)), dim=0)\n",
    "                yield input_data, output_data, i_chunk, i_in_chunk\n",
    "\n",
    "    def get_conditioning_indices(self, index):\n",
    "        return self.conditioning_timesteps + index\n",
    "\n",
    "    def get_target_indices(self, index):\n",
    "        return index + self.lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = Conditional_Dataset_Zarr_Iterable(\"/data/compoundx/WeatherDiff/model_input/079A9C_test.zarr\", \"/data/compoundx/WeatherDiff/config_file/079A9C.yml\", shuffle_chunks=True, shuffle_in_chunks=True)\n",
    "ds2 = Conditional_Dataset(pt_file_path=\"/data/compoundx/WeatherDiff/model_input/278771_test.pt\", config_file_path=\"/data/compoundx/WeatherDiff/config_file/278771.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dss, batch_size=1)\n",
    "dl2 = DataLoader(ds2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "targets = []\n",
    "inputs  = []\n",
    "\n",
    "for ins, tars, i_batch, i_in_batch in dl:\n",
    "    # print(i_batch, i_in_batch)\n",
    "    indices.append(i_in_batch)  \n",
    "    targets.append(tars)\n",
    "    inputs.append(ins)\n",
    "\n",
    "values, idcs = torch.sort(torch.concatenate(indices))\n",
    "\n",
    "targets = torch.concatenate(targets)\n",
    "inputs = torch.concatenate(inputs)\n",
    "\n",
    "targets = targets[idcs]\n",
    "inputs = inputs[idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(targets == ds2[:][1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.extend([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(a, (2,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all targets are exactly identical, only shuffled. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
